{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Weekend Support Agent (Tech Lead Version)\n",
    "-----------------------------------------\n",
    "\n",
    "This agent retrieves knowledge from Confluence and also allows\n",
    "optional \"agent instructions\" to be pulled from a specific Confluence\n",
    "page. This page acts as a system prompt, enabling departments to \n",
    "control agent behavior without touching code.\n",
    "\n",
    "Flow:\n",
    "    START â†’ LoadPromptPage â†’ RetrieveDocs â†’ Summarize â†’ Action â†’ Final â†’ END\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import ConfluenceLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸ”‘ Environment Setup\n",
    "# -----------------------------------------------------------------------------\n",
    "ROOT_DIR = Path(__file__).resolve().parents[1]\n",
    "load_dotenv(ROOT_DIR / \".env\")\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\"OPENAI_API_KEY is not defined in .env\")\n",
    "\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "CONFLUENCE_URL = os.getenv(\"CONFLUENCE_URL\")\n",
    "CONFLUENCE_USER = os.getenv(\"CONFLUENCE_USER\")\n",
    "CONFLUENCE_API_TOKEN = os.getenv(\"CONFLUENCE_API_TOKEN\")\n",
    "CONFLUENCE_SPACE_KEY = os.getenv(\"CONFLUENCE_SPACE_KEY\", \"IT\")\n",
    "CONFLUENCE_PROMPT_PAGE_ID = os.getenv(\"CONFLUENCE_PROMPT_PAGE_ID\", None)  # Optional page ID for instructions\n",
    "\n",
    "llm = ChatOpenAI(model=OPENAI_MODEL)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸ—‚ï¸ State Definition\n",
    "# -----------------------------------------------------------------------------\n",
    "class State(TypedDict):\n",
    "    task: str\n",
    "    lang: str\n",
    "    prompt_instructions: str  # Optional system prompt loaded from Confluence\n",
    "    docs: str\n",
    "    summary: str\n",
    "    action: str\n",
    "    final_summary: str\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸŒ Helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "def lang_prefix(lang: str, es: str, en: str) -> str:\n",
    "    return es if lang == \"es\" else en\n",
    "\n",
    "def _ctx(state: State) -> str:\n",
    "    return f\"Task: {state.get('task','')}\\n\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸ“˜ Confluence Knowledge Base\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_retriever() -> FAISS:\n",
    "    \"\"\"Load Confluence documents into FAISS retriever.\"\"\"\n",
    "    loader = ConfluenceLoader(\n",
    "        url=CONFLUENCE_URL,\n",
    "        username=CONFLUENCE_USER,\n",
    "        api_key=CONFLUENCE_API_TOKEN,\n",
    "        space_key=CONFLUENCE_SPACE_KEY,\n",
    "        include_attachments=False,\n",
    "        limit=100,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "    return db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "retriever = build_retriever()\n",
    "\n",
    "def load_prompt_page() -> str:\n",
    "    \"\"\"Load optional prompt instructions from a dedicated Confluence page.\"\"\"\n",
    "    if not CONFLUENCE_PROMPT_PAGE_ID:\n",
    "        return \"\"\n",
    "    loader = ConfluenceLoader(\n",
    "        url=CONFLUENCE_URL,\n",
    "        username=CONFLUENCE_USER,\n",
    "        api_key=CONFLUENCE_API_TOKEN,\n",
    "        page_ids=[CONFLUENCE_PROMPT_PAGE_ID],  # load only this page\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs[0].page_content if docs else \"\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸ¤– Agent Nodes\n",
    "# -----------------------------------------------------------------------------\n",
    "def prompt_instructions_agent(state: State) -> State:\n",
    "    \"\"\"Load optional system instructions from Confluence.\"\"\"\n",
    "    state[\"prompt_instructions\"] = load_prompt_page()\n",
    "    return state\n",
    "\n",
    "def retrieve_docs(state: State) -> State:\n",
    "    \"\"\"Retrieve relevant docs from Confluence.\"\"\"\n",
    "    query = state.get(\"task\", \"\")\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    state[\"docs\"] = \"\\n\\n\".join([r.page_content for r in results])\n",
    "    return state\n",
    "\n",
    "def summarize_docs(state: State) -> State:\n",
    "    \"\"\"Summarize retrieved docs.\"\"\"\n",
    "    prompt = f\"\"\"{lang_prefix(state['lang'],\n",
    "    \"Explica en lenguaje sencillo lo encontrado en Confluence.\",\n",
    "    \"Summarize the retrieved Confluence documentation in plain language.\")}\n",
    "\n",
    "{_ctx(state)}\n",
    "\n",
    "âš™ï¸ Agent Instructions (if any):\n",
    "{state['prompt_instructions']}\n",
    "\n",
    "ðŸ“š Docs:\n",
    "{state['docs']}\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"summary\"] = result.content\n",
    "    return state\n",
    "\n",
    "def action_step(state: State) -> State:\n",
    "    \"\"\"Suggest one practical action.\"\"\"\n",
    "    prompt = f\"\"\"{lang_prefix(state['lang'],\n",
    "    \"Sugiere una acciÃ³n prÃ¡ctica (â‰¤15 min).\",\n",
    "    \"Suggest one practical action (â‰¤15 min).\")}\n",
    "\n",
    "{_ctx(state)}\n",
    "Summary:\n",
    "{state['summary']}\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"action\"] = result.content\n",
    "    return state\n",
    "\n",
    "def final_summary(state: State) -> State:\n",
    "    \"\"\"Stitch everything together into a final response.\"\"\"\n",
    "    prompt = f\"\"\"{lang_prefix(state['lang'],\n",
    "    \"ðŸ“‹ Respuesta Final de Soporte\",\n",
    "    \"ðŸ“‹ Final Support Answer\")}\n",
    "\n",
    "{_ctx(state)}\n",
    "\n",
    "âš™ï¸ Agent Instructions:\n",
    "{state['prompt_instructions']}\n",
    "\n",
    "ðŸ“š Docs:\n",
    "{state['docs']}\n",
    "\n",
    "ðŸ’¡ Explanation:\n",
    "{state['summary']}\n",
    "\n",
    "âš¡ Suggested Action:\n",
    "{state['action']}\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    state[\"final_summary\"] = result.content\n",
    "    return state\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸ”— Graph Assembly\n",
    "# -----------------------------------------------------------------------------\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"PromptInstructions\", RunnableLambda(prompt_instructions_agent))\n",
    "builder.add_node(\"RetrieveDocs\", RunnableLambda(retrieve_docs))\n",
    "builder.add_node(\"Summarize\", RunnableLambda(summarize_docs))\n",
    "builder.add_node(\"Action\", RunnableLambda(action_step))\n",
    "builder.add_node(\"Final\", RunnableLambda(final_summary))\n",
    "\n",
    "builder.add_edge(START, \"PromptInstructions\")\n",
    "builder.add_edge(\"PromptInstructions\", \"RetrieveDocs\")\n",
    "builder.add_edge(\"RetrieveDocs\", \"Summarize\")\n",
    "builder.add_edge(\"Summarize\", \"Action\")\n",
    "builder.add_edge(\"Action\", \"Final\")\n",
    "builder.add_edge(\"Final\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ðŸš€ Entry Point\n",
    "# -----------------------------------------------------------------------------\n",
    "def run_support(task: str, lang: str = \"en\") -> dict:\n",
    "    \"\"\"Run the Weekend Support pipeline.\"\"\"\n",
    "    state_in: State = {\n",
    "        \"task\": task or \"\",\n",
    "        \"lang\": lang or \"en\",\n",
    "        \"prompt_instructions\": \"\",\n",
    "        \"docs\": \"\",\n",
    "        \"summary\": \"\",\n",
    "        \"action\": \"\",\n",
    "        \"final_summary\": \"\",\n",
    "    }\n",
    "    result: State = graph.invoke(state_in, config={\"configurable\": {\"thread_id\": \"weekend-support\"}})\n",
    "    return {\n",
    "        \"prompt_instructions\": result.get(\"prompt_instructions\", \"\"),\n",
    "        \"docs\": result.get(\"docs\", \"\"),\n",
    "        \"summary\": result.get(\"summary\", \"\"),\n",
    "        \"action\": result.get(\"action\", \"\"),\n",
    "        \"final_summary\": result.get(\"final_summary\", \"\"),\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
